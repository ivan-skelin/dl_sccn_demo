clear

XTrain = load('-mat','/expanse/projects/nemar/dtyoung/DL-EEG/data/child_mind_x_train_2s_24chan_raw.mat');
XTest  = load('-mat','/expanse/projects/nemar/dtyoung/DL-EEG/data/child_mind_x_test_2s_24chan_raw.mat');
XVal   = load('-mat','/expanse/projects/nemar/dtyoung/DL-EEG/data/child_mind_x_val_2s_24chan_raw.mat'); 

YTrain = load('-mat','/expanse/projects/nemar/dtyoung/DL-EEG/data/child_mind_y_train_2s_24chan_raw.mat');
YTest  = load('-mat','/expanse/projects/nemar/dtyoung/DL-EEG/data/child_mind_y_test_2s_24chan_raw.mat');
YVal   = load('-mat','/expanse/projects/nemar/dtyoung/DL-EEG/data/child_mind_y_val_2s_24chan_raw.mat');

XTrain = XTrain.X_train;
XTest  = XTest.X_test;
XVal   = XVal.X_val;

YTrain = categorical(YTrain.Y_train);
YTest  = categorical(YTest.Y_test);
YVal   = categorical(YVal.Y_val);

dsTrain = augmentedImageDatastore([size(XTrain,1) size(XTrain,2) 1], reshape(XTrain, size(XTrain,1), size(XTrain,2), 1, size(XTrain,3)),YTrain');
dsTest  = augmentedImageDatastore([size(XTest ,1) size(XTest ,2) 1], reshape(XTest , size(XTest ,1), size(XTest ,2), 1, size(XTest ,3)),YTest' );
dsVal   = augmentedImageDatastore([size(XVal  ,1) size(XVal  ,2) 1], reshape(XVal  , size(XVal  ,1), size(XVal  ,2), 1, size(XVal  ,3)),YVal' );

convOpts = { 'Padding', 1, 'WeightL2Factor', 0 };
layers2 = [ imageInputLayer([ 24 256], 'Normalization', 'none') ...
        convolution2dLayer(3, 16, convOpts{:}) ...
        reluLayer() ...
        convolution2dLayer(3, 16, convOpts{:}) ...
        reluLayer() ...
        maxPooling2dLayer(2, 'Stride', 2) ...
        convolution2dLayer(3, 32, convOpts{:}) ...
        reluLayer() ...
        convolution2dLayer(3, 32, convOpts{:}) ...
        reluLayer() ...
        maxPooling2dLayer(2, 'Stride', 2) ...
        convolution2dLayer(3, 64, convOpts{:}) ...
        reluLayer() ...
        convolution2dLayer(3, 64, convOpts{:}) ...
        reluLayer() ...    
        convolution2dLayer(3, 64, convOpts{:}) ...
        reluLayer() ...    
        maxPooling2dLayer(2, 'Stride', 2) ...
        fullyConnectedLayer(1024) ...
        reluLayer() ...    
        dropoutLayer(0.5) ...
        fullyConnectedLayer(1024) ...
        reluLayer() ...    
        dropoutLayer(0.5) ...
        fullyConnectedLayer(2) ...
        softmaxLayer() ...
        classificationLayer ];

if 0
    % SVM performance
    XTrainSVM = reshape(XTrain, size(XTrain,1)*size(XTrain,2)*size(XTrain,3), size(XTrain,4))';
    XTestSVM  = reshape(XTest,  size(XTest,1) *size(XTest,2) *size(XTest,3),  size(XTest,4))';
    svm = fitcsvm(gpuArray(XTrainSVM),YTrain,'Standardize',true);
    labels = predict(svm, XTestSVM);
    perf = sum((labels==YTest))/length(labels); % 60% performance
elseif 0
    % Random forest 
    model2 = TreeBagger(100, XTrainSVM, YTrain, 'nprint', 20); % very fast
    labels = predict(model2, XTestSVM);
    perf = sum((labels==YTest))/length(labels); % 82% performance (not better with 1000 trees
elseif 0
    % logisit regression
    [B,FitInfo] = lassoglm(XTrainSVM, YTrain,'binomial','NumLambda',25, 'link','logit', 'CV', 3);
    idxLambdaMinDeviance = FitInfo.IndexMinDeviance;
    B0 = FitInfo.Intercept(idxLambdaMinDeviance);
    coef = [B0; B(:,idxLambdaMinDeviance)];
    yhat = glmval(coef,XTestSVM,'logit');
    yhatBinom = (yhat>=0.5);
    perf = sum(YTest == categorical(yhatBinom+0))/length(yhat); % 81% performance
end

options = trainingOptions('adam', ...
    'InitialLearnRate',0.0005, ...
    'SquaredGradientDecayFactor',0.99, ...
    'MaxEpochs',20, ...
    'MiniBatchSize',70, ...
    'Plots','training-progress',...
     'ValidationData',dsVal);

%% train the network =======================================================

net = trainNetwork(dsTrain,layers2,options);

%% options
miniBatchSize = 64; % power of 2
valFrequency = floor(length(XTrain)/miniBatchSize);
options = trainingOptions('adam', ...
    'MiniBatchSize',miniBatchSize, ...
    'MaxEpochs',70, ...
    'InitialLearnRate', 0.002, ... % 3e-4, Change learning schedule every 30 epochs, divide by 10
    'LearnRateSchedule', 'piecewise', ...
    'LearnRateDropFactor', 0.1, ...
    'LearnRateDropPeriod', 40, ... % or 30
    'ValidationData', dsVal, ...
    'ValidationFrequency', valFrequency, ...
    'Shuffle','every-epoch', ...
    'Verbose',true);
net = trainNetwork(dsTrain,layers2,options);

save('-mat', 'net.mat', 'net');
